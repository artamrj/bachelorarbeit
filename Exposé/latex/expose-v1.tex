\documentclass[12pt,a4paper]{article}

\usepackage[margin=2.5cm]{geometry}
\usepackage{setspace}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{lmodern}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\usepackage[
  backend=biber,
  style=ieee,            % IEEE bibliography formatting
  citestyle=numeric-comp,% [1–3] compression
  sorting=none,          % order of appearance
  maxbibnames=99,        % show all authors in bibliography (or set 6/10)
  minbibnames=1,
  giveninits=true,
  doi=true,              % in CS/IEEE DOIs are useful
  isbn=false,
  url=true,
  urldate=comp,          % print access date for online sources
  date=year              % keep dates short when possible
]{biblatex}

\addbibresource{./references.bib}

\begin{document}
\setlength{\parskip}{0.8em}
\setlength{\parindent}{0pt}

\begin{titlepage}
    \centering
    
    % University Header
    {\Large\textsc{Technische Universität Dortmund}}\\[0.3cm]
    {\large Fakultät für Informatik}\\[0.2cm]
    {\large Studiengang Bachelor Informatik}\\[2cm]
    
    % Document Type
    {\Large\textsc{Exposé zur Bachelorarbeit}}\\[1.5cm]
    
    % Title
    {\LARGE\bfseries Evaluierung von Deployment-Strategien\\[0.3cm] 
    für Industrie~4.0 Anwendungen}\\[0.5cm]
    {\large im Fallstudienkontext des PURIS (Tractus-X) Ökosystems}\\[2cm]
    
    % Information Table
    \begin{tabular}{@{}ll@{}}
        \textbf{Vorgelegt von:} & Mohahammadreza Javadikouchaksaraei \\[3.3em]
        
        \textbf{Erstprüfer:} & Prof. Dr. Falk Howar \\[0.3em]
        \textbf{Zweitprüfer:} & Dr.-Ing. Joachim Hunker \\[0.3em]
        \textbf{Fachlicher Betreuer:} & Haydar Qarawlus, M.Sc. \\
    \end{tabular}
    
    \vfill
    
    % Submission Date
    {\large Eingereicht am: \today}\\[0.5cm]
    {\small Dortmund}
    
    \thispagestyle{empty}
\end{titlepage}

\clearpage
\setcounter{page}{1}
\onehalfspacing

\section{Hintergrund und Motivation}
Der technologische Fortschritt im Cloud-Bereich hat in den letzten Jahren zu einer zunehmenden Komplexität moderner Anwendungen geführt, die heute als Teil von Industry~4.0 betrachtet werden. Dies bedeutet, dass diese Systeme in wachsendem Maße auf vernetzte Softwarekomponenten sowie cloudbasierte Infrastrukturen aufbauen.

Die Deployment solcher Systeme ist aufgrund ihres verteilten, containerisierten und stark abhängigen Charakters mit praktischen Herausforderungen verbunden. Dies wirft zahlreiche Fragen hinsichtlich der Einführung und Umsetzung in Organisationen mit unterschiedlichen Rahmenbedingungen auf. Abhängig vom jeweiligen Kontext reicht das Spektrum möglicher Deployment-Strategien von manuellen Verfahren bis hin zu vollständig automatisierten Ansätzen. Derzeit existiert jedoch nur begrenzte wissenschaftliche Orientierung dazu, wie geeignete Strategien für verschiedene Szenarien ausgewählt und hinsichtlich Komplexität, Wartbarkeit und Zuverlässigkeit bewertet werden können.

Zur Analyse und zum Vergleich solcher Prozesse und Strategien bieten sich Projekte wie Catena-X an, insbesondere Tractus-X sowie die darin enthaltene PURIS-Komponente. Diese fortgeschrittene Anwendung ermöglicht eine Betrachtung aus akademischer und operativer Perspektive.

\section{Problemstellung}
Das Problem besteht nicht im Fehlen von Werkzeugen, sondern in der Frage, welches Werkzeug in welcher Situation angemessen eingesetzt werden sollte. Es mangelt an einer systematischen Analyse und Bewertung von Deployment-Strategien für komplexe containerisierte Anwendungen und verteilte Mikrosysteme. Vorhandene Dokumentationen konzentrieren sich überwiegend auf technische Umsetzungsschritte und bieten keinen strukturierten Ansatz zur Auswahl zwischen manuellen, teilautomatisierten oder vollautomatischen Deployments. Darüber hinaus existiert kein kennzahlenbasiertes Rahmenwerk zur Bewertung dieser Strategien hinsichtlich Komplexität, Aufwand, Zuverlässigkeit, Reproduzierbarkeit und operativer Eigenschaften.

Folglich sehen sich Organisationen und Teams mit hochentwickelten Anwendungen und komplexen Systemarchitekturen mit Unsicherheiten hinsichtlich benötigter Kompetenzprofile, operativer Risiken und der langfristigen Wartbarkeit konfrontiert. Die zentrale Fragestellung liegt darin, wie ein geeigneter Weg gewählt werden kann, was wiederum Raum für vertiefte Forschung und Analyse eröffnet.

\section{Forschungsfragen}

\begin{enumerate}[label=\textbf{RQ\arabic*:}]
    \item Welche Deployment-Strategien sind für containerisierte Industry~4.0-Anwendungen im Kontext von Tractus-X relevant?
    \item Anhand welcher Kriterien lassen sich Deployment-Strategien systematisch evaluieren und vergleichen?
    \item Inwiefern unterscheiden sich manuelle, semi-automatisierte und automatisierte Deployment-Ansätze hinsichtlich der definierten Evaluationskriterien?
    \item Welche Deployment-Strategie eignet sich unter welchen Rahmenbedingungen und aus welchen Gründen?
\end{enumerate}

\section{Zielsetzung}
Die vorliegende Arbeit verfolgt folgende Zielsetzungen:

\begin{enumerate}
    \item \textbf{Entwicklung eines Evaluationsrahmens:} Erarbeitung eines strukturierten Kriterienkatalogs zur systematischen Bewertung von Deployment-Strategien im Kontext containerisierter Anwendungen.
    
    \item \textbf{Prototypische Implementierung:} Umsetzung dreier Deployment-Strategien (manuell, semi-automatisiert, vollautomatisiert) am Beispiel der PURIS-Anwendung innerhalb des Tractus-X-Ökosystems.
    
    \item \textbf{Empirische Evaluation:} Konzeption und Durchführung von Evaluationsszenarien zur Erhebung quantitativer und qualitativer Daten.
    
    \item \textbf{Vergleichende Analyse:} Gegenüberstellung der Deployment-Strategien hinsichtlich der definierten Evaluationskriterien.
    
    \item \textbf{Ableitung von Handlungsempfehlungen:} Formulierung praxisorientierter Empfehlungen für die Strategieauswahl in industriellen Anwendungsszenarien.
\end{enumerate}



\newpage

\section{Methodik}
Die Methodik gliedert sich in vier Phasen:

\subsection*{1. Strategie-Definition}
Es werden drei Deployment-Strategien umgesetzt:
\begin{itemize}
    \item \textbf{Manuell:} direkter Helm-/CLI-basierter Ablauf,
    \item \textbf{Semi-automatisiert:} script-gesteuerte Orchestrierung über Bash und/oder Ansible,
    \item \textbf{Automatisiert:} deklaratives Deployment über GitOps/CI/CD (z.\,B. ArgoCD oder Flux).
\end{itemize}

\subsection*{2. Szenarien-Design}
Es werden drei Szenarien mit steigender Integrationstiefe betrachtet:
\begin{itemize}
    \item \textbf{Szenario A (geringe Integrationstiefe):} Einzelinstanz von PURIS in lokaler Umgebung,
    \item \textbf{Szenario B (moderate Integrationstiefe):} Multi-Instanz-Deployment mit externen Abhängigkeiten (IDP, Wallet, Tractus-X Umbrella),
    \item \textbf{Szenario C (hohe Integrationstiefe):} vollständiges Lifecycle-Management mit automatisierter Reconciliation (optional IaC-Integration).
\end{itemize}

\subsection*{3. Metriken und Evaluationsrahmen}
Die Evaluation nutzt fünf übergeordnete Metrik-Kategorien:
\begin{description}
    \item[Komplexität] Komponenten, Konfigurationsschritte, Abhängigkeiten
    \item[Aufwand] Zeitbedarf, erforderliche Fähigkeiten, Dokumentationsbedarf
    \item[Zuverlässigkeit] Fehlerquoten, Rollback-Fähigkeit, Sicherheitsaspekte
    \item[Reproduzierbarkeit] Konsistenz, Determinismus, Konfigurationsdrift
    \item[Operierbarkeit] Skalierung, Monitoring, Upgrades, Integration, Kosten
\end{description}

Die Datenerhebung umfasst Zeitmessungen, Fehlerprotokolle, Log-Analysen, Dokumentationsauswertung und qualitative Beobachtungen.

\subsection*{4. Vergleichende Analyse}
Die Resultate werden mittels
\begin{itemize}
    \item \textbf{quantitativer Evaluation} (Zeit, Fehler, Schritte, usw.)
    \item \textbf{qualitativer Evaluation} (Wartbarkeit, Lernkurve, usw.)
\end{itemize}
analysiert. Die Erkenntnisse beantworten die Forschungsfragen und leiten Empfehlungen ab.

\section{Erwartete Ergebnisse}
Die Arbeit liefert:
\begin{itemize}
    \item eine strukturierte Taxonomie von Deployment-Strategien für Industrie~4.0,
    \item ein wiederverwendbares, metrikenbasiertes Evaluationsmodell,
    \item szenariobasierte Implementierungsergebnisse für PURIS,
    \item praktische Handlungsempfehlungen für industrielle Einsatzszenarien.
\end{itemize}

\section{Einschränkungen}
Zur Wahrung der Durchführbarkeit gilt:
\begin{itemize}
    \item es wird nur eine Fallstudie (PURIS?? oder Umbrella??) untersucht,
    \item eine produktionsnahe industrielle Validierung liegt außerhalb des Umfangs,
    \item die Sicherheitsbewertung beschränkt sich auf Deployment-Ebene,
    \item die IaC-Evaluation ist optional.
\end{itemize}

\newpage

\section{Gliederung der Arbeit}
\begin{enumerate}[label=\arabic*.,ref=\arabic*]
    \item \textbf{Einleitung}
    \begin{enumerate}[label=\arabic{enumi}.\arabic*.,ref=\arabic{enumi}.\arabic*]
        \item Motivation
        \item Problemstellung
        \item Forschungsfragen
        \item Aufbau der Arbeit und Vorgehensweise
    \end{enumerate}

    \item \textbf{Theoretischer Hintergrund}
    \begin{enumerate}[label=\arabic{enumi}.\arabic*.,ref=\arabic{enumi}.\arabic*]
        \item Industrie 4.0
        \item Containerisierte Systeme und Kubernetes
        \item Deployment-Strategien und -Methoden: manuell, semi-automatisiert, automatisiert und (IaC optional)
        \item Metriken für die Evaluation
    \end{enumerate}

    \item \textbf{Fallstudie: PURIS/UMBRELLA (Tractus-X)}
    \begin{enumerate}[label=\arabic{enumi}.\arabic*.,ref=\arabic{enumi}.\arabic*]
        \item Überblick über das System und seine Komponenten
        \item Anforderungen und Herausforderungen beim Deployment
    \end{enumerate}

    \item \textbf{Methodik}
    \begin{enumerate}[label=\arabic{enumi}.\arabic*.,ref=\arabic{enumi}.\arabic*]
        \item Beschreibung der Methoden für manuelles, semi-automatisiertes und automatisiertes Deployment
        \item Definition der Evaluationsmetriken
        \item Szenarien für die Deployment-Implementierung
    \end{enumerate}

    \item \textbf{Deployments und Szenarien}
    \begin{enumerate}[label=\arabic{enumi}.\arabic*.,ref=\arabic{enumi}.\arabic*]
        \item Manuelles Deployment
        \item Semi-automatisiertes Deployment
        \item Automatisiertes Deployment
        \item Vergleich von IaC-Tools (optional)
    \end{enumerate}

    \item \textbf{Evaluation und Analyse}
    \begin{enumerate}[label=\arabic{enumi}.\arabic*.,ref=\arabic{enumi}.\arabic*]
        \item Darstellung der Ergebnisse basierend auf den Metriken
        \item Vergleich der Deployment-Strategien
        \begin{enumerate}[label=\arabic{enumi}.\arabic{enumii}.\arabic*.,ref=\arabic{enumi}.\arabic{enumii}.\arabic*]
            \item Qualitative Analyse
            \item Quantitative Analyse
        \end{enumerate}
        \item Diskussion der Vor- und Nachteile jeder Strategie
        \item Diskussion der Ergebnisse
        \begin{enumerate}[label=\arabic{enumi}.\arabic{enumii}.\arabic*.,ref=\arabic{enumi}.\arabic{enumii}.\arabic*]
            \item Beantwortung der Forschungsfragen
        \end{enumerate}
    \end{enumerate}

    \item \textbf{Fazit und Empfehlungen}
    \begin{enumerate}[label=\arabic{enumi}.\arabic*.,ref=\arabic{enumi}.\arabic*]
        \item Zusammenfassung der wichtigsten Erkenntnisse
        \item Empfehlungen für Anwender in Industrieumgebungen
    \end{enumerate}
\end{enumerate}

\section{Vorläufiger Zeitplan}

\begin{center}
\begin{tabular}{@{}p{10.5cm}r@{}}
\toprule
\textbf{Phase} & \textbf{Dauer} \\
\midrule
Literaturrecherche und theoretische Einarbeitung & 2--3 Wochen \\
Definition der Deployment-Szenarien und Evaluationsmetriken & 1--2 Wochen \\
Implementierung der Deployment-Strategien (manuell, semi-automatisiert, automatisiert) & 3--5 Wochen \\
Durchführung der Evaluation und Analyse der Ergebnisse & 2--3 Wochen \\
Ausarbeitung des Abschlussberichts sowie Überarbeitung und Korrekturen & 2--3 Wochen \\
\midrule
\textbf{Gesamt} & \textbf{12--16 Wochen} \\
\bottomrule
\end{tabular}
\end{center}


\section{Vorläufige Literatur}
\nocite{*}
\printbibliography[heading=none]

\end{document}
